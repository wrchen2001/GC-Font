# GC-Font: Few-Shot Font Generation via Global Contextual Feature Modelling (BMVC 2025)

Official Pytorch Implementation of **"GC-Font: Few-Shot Font Generation via Global Contextual Feature Modelling"** by Weiran Chen, Guiqian Zhu, Ying Li, Yi Ji and Chunping Liu.

## Abstract

Few-shot font generation aims to create new fonts with a limited number of glyph references. It can be used to greatly reduce the labour cost of manual font design. However, due to the variety and complexity of font styles, the results generated by existing methods often suffer from visible defects, such as stroke errors, blurriness or distorted shapes. To address these issues, we propose GC-Font, a novel framework which integrates a Global Contextual Feature Modelling (GCFM) module. Specifically, this module is inserted between the content encoder and decoder, where it fuses convolution and attention mechanisms to process intermediate feature maps and injects enhanced global contextual features into the decoder. Moreover, we apply adaptive convolutions to the low-level feature maps from the content encoder to strengthen contextual correlations. In addition, a skeleton consistency loss and an edge consistency loss are also designed to improve geometric alignment. Extensive experiments reveal that our GC-Font outperforms the state-of-the-art methods in both qualitative and quantitative evaluations, demonstrating its effectiveness on diverse font styles.

<div align="center">
  <img src="/Paper_IMG/Task_definition.jpg" width="70%">
</div>

## Dependencies

> python >= 3.8  
> torch >= 1.7.1  
> torchvision >= 0.8.2  
> sconf >= 0.2.5  
> lmdb >= 1.6.2  
> opencv-python >= 4.10.0.84  
> scipy >= 1.10.1

## Data Preparation
### Images and Characters
1)  First, collect a set of font files in .ttf (TrueType Font) or .otf (OpenType Font) format. These fonts should be divided into three groups: content font, training fonts, and validation fonts. To ensure the model effectively learns style variations, it's recommended that the training fonts exhibit noticeable style diversity. In our experiments, the fonts were sourced from [here](https://www.foundertype.com/).  

2)  Next, determine the target character set for both training and testing. For example, the first-level Chinese character set contains 3500 commonly used characters:

 >{雾、隐、枫、桥、月、花、落、砚、池、春、笛、悠、云、外、客、墨、染、故、人、心、...、etc}

3)  Once the fonts and characters are prepared, use the script ```./datasets/font2image.py``` to render character images from the fonts. The directory structure should be organized as follows:
```
Font Directory
|-- content
|   |-- content_font
|   |   |-- content_font_char1.png
|   |   |-- content_font_char2.png
|   |   |-- ...
|-- train
|   |-- train_font1
|   |-- train_font2
|   |-- train_font3
|   |   |-- train_font3_char1.png
|   |   |-- train_font3_char2.png
|   |   |-- ...
|   |-- ...
|-- val
|   |-- val_font1
|   |-- val_font2
|   |-- val_font3
|   |   |-- val_font3_char1.png
|   |   |-- val_font3_char2.png
|   |   |-- ...
|   |-- ...
```

### Construct meta files and LMDB environment
1. The characters need to be split into training and validation sets, with each character saved in Unicode format. You can convert characters to Unicode using ```hex(ord(ch))[2:].upper():```, examples can be found in ```./meta/```.

2. Execute the following command to generate the LMDB files:
```
  python3 ./build_dataset/build_meta4train.py \
  --saving_dir ./results/your_task_name/ \
  --content_font path\to\content \
  --train_font_dir path\to\training_font \
  --val_font_dir path\to\validation_font \
  --seen_unis_file path\to\train_unis.json \
  --unseen_unis_file path\to\val_unis.json 
  ```

## Training Workflow

The overall training is divided into two stages:  
1. Pre-training the content encoder and codebook based on [RQ-VAE](https://arxiv.org/abs/2203.01941).  
2. Training the few-shot font generation framework with [GAN](https://dl.acm.org/doi/abs/10.1145/3422622).  
### Pre-train the RQ-VAE
The RQ-VAE is trained using the content font. The relevant training code is provided at ```RQ-VAE.py```.

Once RQ-VAE pre-training is complete, use the trained content encoder to compute similarity scores between each character in the training and validation sets. The similarity information is stored in a dictionary format, for example:
> {'4E07': {'4E01': 0.2143, '4E03': 0.2374, ...}, '4E08': {'4E01': 0.1137, '4E03': 0.1020, ...}, ...}


### Train the GC-Font

Adjust the configuration file as needed in the file ```./cfgs/custom.yaml```

Some Key Configuration Options:
* work_dir: Directory to store all output results. (should match the saving_dir used during dataset preparation) 
* data_path: Path to the LMDB dataset. (`saving_dir/lmdb`)
* data_meta: Path to the meta information. (`saving_dir/meta`)
* content_font: Specify the source font to be used.
* all_content_char_json: JSON file listing all characters from both training and validation sets.
* other values are hyperparameters for training.

Launch Training
 ```
  python3 train.py task_name cfgs/custom.yaml
    #--resume \path\to\your\pretrain_model.pdparams
  ```

Note on Modules Classes:

During RQ-VAE pretraining, the Decoder (and Encoder) is a standard version without attention.

For main model training, the Decoder (and Encoder) is modified to integrate attention features.

Pretrained weights must be loaded before the main training phase.


## Infer the GC-Font

Run the script
```
  python3 inference.py ./cfgs/custom.yaml \
  --weight \path\to\saved_model.pdparams \
  --content_font \path\to\content_imgs \
  --img_path \path\to\test_imgs \
  --saving_root ./infer_res
  ```

## Acknowledgements
Our project is inspired and modified by [VQ-Font](https://github.com/awei669/VQ-Font) and [FsFont](https://github.com/tlc121/FsFont). We would like to express our sincere gratitude to our collaborators for their valuable supports and to the reviewers for their insightful feedback and suggestions.

## Citation

```
@InProceedings{Chen_2025_BMVC,
    author    = {Weiran Chen and Guiqian Zhu and Ying Li and Yi Ji and Chunping Liu},
    title     = {GC-Font: Few-Shot Font Generation via Global Contextual Feature Modelling},
    booktitle = {Proceedings of the 36th British Machine Vision Conference, {BMVC}},
    month     = {November},
    year      = {2025},
    pages     = {xxxx-xxxx}
}
```

## Contact

If you have any questions, please feel free to contact wrchen2023@stu.suda.edu.cn or wrchen2023@outlook.com.
